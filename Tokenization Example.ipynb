{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62357c68-eb6a-4704-aa39-b7f74c2a5515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\swabh\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\swabh\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\swabh\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\swabh\\anaconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\swabh\\anaconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\swabh\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff9afaf-ffaf-468f-9317-7ee174236d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"Corpus is a large collection of structured or unstructured text data used in Natural Language Processing (NLP).\n",
    "It is used to train, test, and evaluate NLP models.\n",
    "A corpus may include books, articles, emails, reviews, or social media text.\n",
    "Examples include NLTK Corpus, Wikipedia Corpus, and News Corpus.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1c5e1b-2ae1-499f-81dd-e062549e9a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is a large collection of structured or unstructured text data used in Natural Language Processing (NLP).\n",
      "It is used to train, test, and evaluate NLP models.\n",
      "A corpus may include books, articles, emails, reviews, or social media text.\n",
      "Examples include NLTK Corpus, Wikipedia Corpus, and News Corpus.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1db556e0-acf5-47ab-8877-84137748c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenisation\n",
    "## Sentence --> paragraphs\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49e7a00e-6fdb-4d9e-9b6a-e47f642ef857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corpus is a large collection of structured or unstructured text data used in Natural Language Processing (NLP).',\n",
       " 'It is used to train, test, and evaluate NLP models.',\n",
       " 'A corpus may include books, articles, emails, reviews, or social media text.',\n",
       " 'Examples include NLTK Corpus, Wikipedia Corpus, and News Corpus.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df70acce-970b-4cd0-b11f-714c3fb7599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37453785-edf3-468d-9f11-88b4b2aed193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corpus is a large collection of structured or unstructured text data used in Natural Language Processing (NLP).',\n",
       " 'It is used to train, test, and evaluate NLP models.',\n",
       " 'A corpus may include books, articles, emails, reviews, or social media text.',\n",
       " 'Examples include NLTK Corpus, Wikipedia Corpus, and News Corpus.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0d236c-3bcc-4a29-b6f8-78909baae828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5347e601-da82-4506-baef-12454ae4dd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is a large collection of structured or unstructured text data used in Natural Language Processing (NLP).\n",
      "It is used to train, test, and evaluate NLP models.\n",
      "A corpus may include books, articles, emails, reviews, or social media text.\n",
      "Examples include NLTK Corpus, Wikipedia Corpus, and News Corpus.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba458fd-8cad-420f-b782-5ac32d6db4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tokenization\n",
    "## Paragraph --> words\n",
    "## sentence ----> words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf2f650-1b8c-4a26-842d-f29d88f2a8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corpus',\n",
       " 'is',\n",
       " 'a',\n",
       " 'large',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'structured',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'data',\n",
       " 'used',\n",
       " 'in',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'used',\n",
       " 'to',\n",
       " 'train',\n",
       " ',',\n",
       " 'test',\n",
       " ',',\n",
       " 'and',\n",
       " 'evaluate',\n",
       " 'NLP',\n",
       " 'models',\n",
       " '.',\n",
       " 'A',\n",
       " 'corpus',\n",
       " 'may',\n",
       " 'include',\n",
       " 'books',\n",
       " ',',\n",
       " 'articles',\n",
       " ',',\n",
       " 'emails',\n",
       " ',',\n",
       " 'reviews',\n",
       " ',',\n",
       " 'or',\n",
       " 'social',\n",
       " 'media',\n",
       " 'text',\n",
       " '.',\n",
       " 'Examples',\n",
       " 'include',\n",
       " 'NLTK',\n",
       " 'Corpus',\n",
       " ',',\n",
       " 'Wikipedia',\n",
       " 'Corpus',\n",
       " ',',\n",
       " 'and',\n",
       " 'News',\n",
       " 'Corpus',\n",
       " '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "457fbcec-462c-4a56-80fd-725933c5a99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is a large collection of structured or unstructured text data used in Natural Language Processing (NLP).\n",
      "It is used to train, test, and evaluate NLP models.\n",
      "A corpus may include books, articles, emails, reviews, or social media text.\n",
      "Examples include NLTK Corpus, Wikipedia Corpus, and News Corpus.\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a04c59f9-c689-4b72-bd9c-6b33b9dcf8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corpus', 'is', 'a', 'large', 'collection', 'of', 'structured', 'or', 'unstructured', 'text', 'data', 'used', 'in', 'Natural', 'Language', 'Processing', '(', 'NLP', ')', '.']\n",
      "['It', 'is', 'used', 'to', 'train', ',', 'test', ',', 'and', 'evaluate', 'NLP', 'models', '.']\n",
      "['A', 'corpus', 'may', 'include', 'books', ',', 'articles', ',', 'emails', ',', 'reviews', ',', 'or', 'social', 'media', 'text', '.']\n",
      "['Examples', 'include', 'NLTK', 'Corpus', ',', 'Wikipedia', 'Corpus', ',', 'and', 'News', 'Corpus', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b43c6df-5827-46b9-9e15-6f343f6d74fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4f1694d-9297-47e6-bf39-448be1812117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corpus',\n",
       " 'is',\n",
       " 'a',\n",
       " 'large',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'structured',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'data',\n",
       " 'used',\n",
       " 'in',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ').',\n",
       " 'It',\n",
       " 'is',\n",
       " 'used',\n",
       " 'to',\n",
       " 'train',\n",
       " ',',\n",
       " 'test',\n",
       " ',',\n",
       " 'and',\n",
       " 'evaluate',\n",
       " 'NLP',\n",
       " 'models',\n",
       " '.',\n",
       " 'A',\n",
       " 'corpus',\n",
       " 'may',\n",
       " 'include',\n",
       " 'books',\n",
       " ',',\n",
       " 'articles',\n",
       " ',',\n",
       " 'emails',\n",
       " ',',\n",
       " 'reviews',\n",
       " ',',\n",
       " 'or',\n",
       " 'social',\n",
       " 'media',\n",
       " 'text',\n",
       " '.',\n",
       " 'Examples',\n",
       " 'include',\n",
       " 'NLTK',\n",
       " 'Corpus',\n",
       " ',',\n",
       " 'Wikipedia',\n",
       " 'Corpus',\n",
       " ',',\n",
       " 'and',\n",
       " 'News',\n",
       " 'Corpus',\n",
       " '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb99f87c-80e1-4104-a3b9-0f1ca790b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f384f11e-6201-4fbf-898d-faf15ede1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27f24924-6122-46af-9794-fd330b7d9c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Corpus',\n",
       " 'is',\n",
       " 'a',\n",
       " 'large',\n",
       " 'collection',\n",
       " 'of',\n",
       " 'structured',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'text',\n",
       " 'data',\n",
       " 'used',\n",
       " 'in',\n",
       " 'Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'used',\n",
       " 'to',\n",
       " 'train',\n",
       " ',',\n",
       " 'test',\n",
       " ',',\n",
       " 'and',\n",
       " 'evaluate',\n",
       " 'NLP',\n",
       " 'models.',\n",
       " 'A',\n",
       " 'corpus',\n",
       " 'may',\n",
       " 'include',\n",
       " 'books',\n",
       " ',',\n",
       " 'articles',\n",
       " ',',\n",
       " 'emails',\n",
       " ',',\n",
       " 'reviews',\n",
       " ',',\n",
       " 'or',\n",
       " 'social',\n",
       " 'media',\n",
       " 'text.',\n",
       " 'Examples',\n",
       " 'include',\n",
       " 'NLTK',\n",
       " 'Corpus',\n",
       " ',',\n",
       " 'Wikipedia',\n",
       " 'Corpus',\n",
       " ',',\n",
       " 'and',\n",
       " 'News',\n",
       " 'Corpus',\n",
       " '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ff35e-18e1-4ea7-b46b-4a5b1ee46bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
